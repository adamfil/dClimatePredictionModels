{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ce2784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing, SimpleExpSmoothing\n",
    "import numpy as np\n",
    "    \n",
    "def temp_prediction(days_in_future: int, lat: int, long: int):\n",
    "    #fetch data \n",
    "    dataset = 'prismc-tmax-daily'\n",
    "    my_token = 'eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJleHAiOjI1MzQwMjMwMDc5OSwiaWF0IjoxNjMwNTMwMTgwLCJzdWIiOiJhMDIzYjUwYi0wOGQ2LTQwY2QtODNiMS1iMTExZDA2Mzk1MmEifQ.qHy4B0GK22CkYOTO8gsxh0YzE8oLMMa6My8TvhwhxMk'\n",
    "\n",
    "    my_url = 'https://api.dclimate.net/apiv3/grid-history/' + dataset + '/' + str(lat) + '_' + str(long)\n",
    "    head = {\"Authorization\": my_token}\n",
    "    r = requests.get(my_url, headers=head)\n",
    "    data = r.json()[\"data\"]\n",
    "    index = pd.to_datetime(list(data.keys()))\n",
    "    values = [float(s.split()[0]) if s else None for s in data.values()]\n",
    "    series = pd.Series(values, index=index)\n",
    "    df = series.to_frame(name='Value')\n",
    "    df = df[~df.index.astype(str).str.contains('02-29')]\n",
    "\n",
    "    #algorithm \n",
    "    hw_model = ExponentialSmoothing(df[\"Value\"],\n",
    "                              trend    =\"add\",\n",
    "                              seasonal = \"add\", \n",
    "                              seasonal_periods=365, \n",
    "                              damped=False).fit(use_boxcox='log')\n",
    "\n",
    "    hw_fitted = hw_model.fittedvalues\n",
    "\n",
    "    hw_resid = hw_model.resid\n",
    "\n",
    "    #Adding the mean of the residuals to correct the bias.\n",
    "    py_hw = hw_model.forecast(days_in_future) + np.mean(hw_resid)\n",
    "\n",
    "    #output\n",
    "    return(py_hw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3081850e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-74207ececd82>:22: FutureWarning: the 'damped'' keyword is deprecated, use 'damped_trend' instead\n",
      "  hw_model = ExponentialSmoothing(df[\"Value\"],\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:427: FutureWarning: After 0.13 initialization must be handled at model creation\n",
      "  warnings.warn(\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:1112: FutureWarning: Setting use_boxcox during fit has been deprecated and will be removed after 0.13. It must be set during model initialization.\n",
      "  warnings.warn(\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:376: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  warnings.warn('No supported index is available.'\n"
     ]
    }
   ],
   "source": [
    "prediction = temp_prediction(365, 40, -120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f77fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15003    49.855505\n",
      "15004    49.584805\n",
      "15005    49.513745\n",
      "15006    51.282396\n",
      "15007    52.350055\n",
      "           ...    \n",
      "15363    48.681371\n",
      "15364    49.641515\n",
      "15365    49.524489\n",
      "15366    50.603692\n",
      "15367    50.635886\n",
      "Length: 365, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e577e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prediction.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62939893",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lat'] = 40\n",
    "df['long'] = -120 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65b87e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  lat  long\n",
      "15003  49.855505   40  -120\n",
      "15004  49.584805   40  -120\n",
      "15005  49.513745   40  -120\n",
      "15006  51.282396   40  -120\n",
      "15007  52.350055   40  -120\n",
      "...          ...  ...   ...\n",
      "15363  48.681371   40  -120\n",
      "15364  49.641515   40  -120\n",
      "15365  49.524489   40  -120\n",
      "15366  50.603692   40  -120\n",
      "15367  50.635886   40  -120\n",
      "\n",
      "[365 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc34866",
   "metadata": {},
   "source": [
    "# Now we have a dataframe for lat/long (-40,120). Now lets make a dataframe for a different lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7075376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-74207ececd82>:22: FutureWarning: the 'damped'' keyword is deprecated, use 'damped_trend' instead\n",
      "  hw_model = ExponentialSmoothing(df[\"Value\"],\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:427: FutureWarning: After 0.13 initialization must be handled at model creation\n",
      "  warnings.warn(\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:1112: FutureWarning: Setting use_boxcox during fit has been deprecated and will be removed after 0.13. It must be set during model initialization.\n",
      "  warnings.warn(\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:920: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "C:\\Users\\filip\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:376: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  warnings.warn('No supported index is available.'\n"
     ]
    }
   ],
   "source": [
    "prediction = temp_prediction(365, 39, -115)\n",
    "df2 = prediction.to_frame()\n",
    "df2['lat'] = 39\n",
    "df2['long'] = -115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5929c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  lat  long\n",
      "15003  45.041420   39  -115\n",
      "15004  45.290030   39  -115\n",
      "15005  46.125934   39  -115\n",
      "15006  45.783243   39  -115\n",
      "15007  46.166201   39  -115\n",
      "...          ...  ...   ...\n",
      "15363  42.588646   39  -115\n",
      "15364  43.604152   39  -115\n",
      "15365  42.841732   39  -115\n",
      "15366  43.206573   39  -115\n",
      "15367  44.118843   39  -115\n",
      "\n",
      "[365 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58934443",
   "metadata": {},
   "source": [
    "# Now we have 2 different dataframes. We can keep doing this until we have a dataframe for each city. Now, lets concatenate these dataframes together. the latitude and longitude which I chose correspond to the towns of omira and lund, so i will put these as keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d897d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df, df2]\n",
    "result = pd.concat(frames, keys = [\"omira - california\", \"lund-nevada\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "315a5c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  0  lat  long\n",
      "omira - california 15003  49.855505   40  -120\n",
      "                   15004  49.584805   40  -120\n",
      "                   15005  49.513745   40  -120\n",
      "                   15006  51.282396   40  -120\n",
      "                   15007  52.350055   40  -120\n",
      "...                             ...  ...   ...\n",
      "lund-nevada        15363  42.588646   39  -115\n",
      "                   15364  43.604152   39  -115\n",
      "                   15365  42.841732   39  -115\n",
      "                   15366  43.206573   39  -115\n",
      "                   15367  44.118843   39  -115\n",
      "\n",
      "[730 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b69c98",
   "metadata": {},
   "source": [
    "# Now we have 1 dataframe which contains all of our predictions, and has our cities as keys. Now lets save as pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de94f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_pickle('test_frame.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830f459",
   "metadata": {},
   "source": [
    "# Now, we have a pickle saved in the current directory. Now lets open the pickle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b131f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_open = pd.read_pickle('test_frame.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac1fb79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  0  lat  long\n",
      "omira - california 15003  49.855505   40  -120\n",
      "                   15004  49.584805   40  -120\n",
      "                   15005  49.513745   40  -120\n",
      "                   15006  51.282396   40  -120\n",
      "                   15007  52.350055   40  -120\n",
      "...                             ...  ...   ...\n",
      "lund-nevada        15363  42.588646   39  -115\n",
      "                   15364  43.604152   39  -115\n",
      "                   15365  42.841732   39  -115\n",
      "                   15366  43.206573   39  -115\n",
      "                   15367  44.118843   39  -115\n",
      "\n",
      "[730 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_open)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb51a7",
   "metadata": {},
   "source": [
    "# And we have our dataframe again. This is how we can use pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8764ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
